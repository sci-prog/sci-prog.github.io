<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="preload" href="/component---src-layouts-index-js-65ee3ce0b05326dad154.js" as="script"/><link rel="preload" href="/component---src-templates-blog-post-js-27856d6eb5844d506e82.js" as="script"/><link rel="preload" href="/path---meltdown-36ea1df735d2937b866a.js" as="script"/><link rel="preload" href="/app-5204eebb1ac2e4e0fdd9.js" as="script"/><link rel="preload" href="/commons-3cf304937523a964e309.js" as="script"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true">Meltdown: Una explicación técnica y sencilla | Scientific Programming Blog</title><style id="typography.js">html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{font:125%/1.45 'Quattrocento Sans',serif;box-sizing:border-box;overflow-y:scroll;}*{box-sizing:inherit;}*:before{box-sizing:inherit;}*:after{box-sizing:inherit;}body{color:hsla(0,0%,0%,0.8);font-family:'Quattrocento Sans',serif;font-weight:400;word-wrap:break-word;font-kerning:normal;-moz-font-feature-settings:"kern", "liga", "clig", "calt";-ms-font-feature-settings:"kern", "liga", "clig", "calt";-webkit-font-feature-settings:"kern", "liga", "clig", "calt";font-feature-settings:"kern", "liga", "clig", "calt";}img{max-width:100%;margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}h1{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;color:hsla(0,0%,0%,0.9);font-family:'Work Sans',sans-serif;font-weight:600;text-rendering:optimizeLegibility;font-size:2rem;line-height:1.1;}h2{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;color:hsla(0,0%,0%,0.9);font-family:'Work Sans',sans-serif;font-weight:600;text-rendering:optimizeLegibility;font-size:1.51572rem;line-height:1.1;}h3{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;color:hsla(0,0%,0%,0.9);font-family:'Work Sans',sans-serif;font-weight:600;text-rendering:optimizeLegibility;font-size:1.31951rem;line-height:1.1;}h4{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;color:hsla(0,0%,0%,0.9);font-family:'Work Sans',sans-serif;font-weight:600;text-rendering:optimizeLegibility;font-size:1rem;line-height:1.1;}h5{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;color:hsla(0,0%,0%,0.9);font-family:'Work Sans',sans-serif;font-weight:600;text-rendering:optimizeLegibility;font-size:0.87055rem;line-height:1.1;}h6{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;color:hsla(0,0%,0%,0.9);font-family:'Work Sans',sans-serif;font-weight:600;text-rendering:optimizeLegibility;font-size:0.81225rem;line-height:1.1;}hgroup{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}ul{margin-left:1.45rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;list-style-position:outside;list-style-image:none;}ol{margin-left:1.45rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;list-style-position:outside;list-style-image:none;}dl{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}dd{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}p{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}figure{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}pre{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;font-size:0.85rem;line-height:1.45rem;}table{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;font-size:1rem;line-height:1.45rem;border-collapse:collapse;width:100%;}fieldset{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}blockquote{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0.90625rem;padding-right:0;padding-top:0;margin-bottom:1.45rem;font-size:1.1487rem;line-height:1.45rem;border-left:0.54375rem solid #1ca086;color:hsla(0,0%,0%,0.65);font-style:italic;}form{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}noscript{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}iframe{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}hr{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:calc(1.45rem - 1px);background:hsla(0,0%,0%,0.2);border:none;height:1px;}address{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.45rem;}b{font-weight:700;}strong{font-weight:700;}dt{font-weight:700;}th{font-weight:700;}li{margin-bottom:calc(1.45rem / 2);}ol li{padding-left:0;}ul li{padding-left:0;}li > ol{margin-left:1.45rem;margin-bottom:calc(1.45rem / 2);margin-top:calc(1.45rem / 2);}li > ul{margin-left:1.45rem;margin-bottom:calc(1.45rem / 2);margin-top:calc(1.45rem / 2);}blockquote *:last-child{margin-bottom:0;}li *:last-child{margin-bottom:0;}p *:last-child{margin-bottom:0;}li > p{margin-bottom:calc(1.45rem / 2);}code{font-size:0.85rem;line-height:1.45rem;}kbd{font-size:0.85rem;line-height:1.45rem;}samp{font-size:0.85rem;line-height:1.45rem;}abbr{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}acronym{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}abbr[title]{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;text-decoration:none;}thead{text-align:left;}td,th{text-align:left;border-bottom:1px solid hsla(0,0%,0%,0.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding-left:0.96667rem;padding-right:0.96667rem;padding-top:0.725rem;padding-bottom:calc(0.725rem - 1px);}th:first-child,td:first-child{padding-left:0;}th:last-child,td:last-child{padding-right:0;}a{color:#1ca086;text-decoration:none;text-shadow:.03em 0 #fff,-.03em 0 #fff,0 .03em #fff,0 -.03em #fff,.06em 0 #fff,-.06em 0 #fff,.09em 0 #fff,-.09em 0 #fff,.12em 0 #fff,-.12em 0 #fff,.15em 0 #fff,-.15em 0 #fff;background-image:linear-gradient(to top, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0) 1px, #1ca086 1px, #1ca086 2px, rgba(0, 0, 0, 0) 2px);}a:hover,a:active{text-shadow:none;background-image:none;}h1,h2,h3,h4,h5,h6{margin-top:2.175rem;margin-bottom:0.725rem;}blockquote > :last-child{margin-bottom:0;}blockquote cite{font-size:1rem;line-height:1.45rem;color:hsla(0,0%,0%,0.8);font-style:normal;font-weight:400;}blockquote cite:before{content:"— ";}@media only screen and (max-width:480px){html{font-size:106.25%;line-height:1.45;}blockquote{border-left:0.27187rem solid #1ca086;color:hsla(0,0%,0%,0.59);padding-left:0.81563rem;font-style:italic;margin-left:-1.0875rem;margin-right:0;}}</style><link href="//fonts.googleapis.com/css?family=Work+Sans:600|Quattrocento+Sans:400,400i,700" rel="stylesheet" type="text/css"/><style id="gatsby-inlined-css">code[class*=language-],pre[class*=language-]{color:#000;background:none;text-shadow:0 1px #fff;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-]::-moz-selection,code[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-]::selection,code[class*=language-] ::selection,pre[class*=language-]::selection,pre[class*=language-] ::selection{text-shadow:none;background:#b3d4fc}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#a67f59;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.author-bio{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;padding:0;margin-bottom:1.45rem}img.author-bio-picture{width:4em;height:4em;border-radius:2em;margin:0}.author-bio-details{margin-left:1em;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center}.author-bio-details p{margin:0}.author-bio-details small{color:gray}</style></head><body><div id="___gatsby"><div style="max-width:34.8rem;margin-left:auto;margin-right:auto;padding:2.175rem 1.0875rem;" data-reactroot="" data-reactid="1" data-react-checksum="-445658269"><h3 style="font-family:Montserrat, sans-serif;margin-top:0;margin-bottom:-1.45rem;" data-reactid="2"><a style="box-shadow:none;text-decoration:none;color:inherit;" href="/" data-reactid="3">Scientific Programming Blog</a></h3><div data-reactid="4"><!-- react-empty: 5 --><h1 data-reactid="6">Meltdown: Una explicación técnica y sencilla</h1><p style="font-size:0.87055rem;line-height:1.45rem;display:block;margin-bottom:0.725rem;margin-top:0.725rem;" data-reactid="7">January 08, 2018</p><div class="author-bio" data-reactid="8"><img class="author-bio-picture" src="https://avatars2.githubusercontent.com/u/6975120?s=400&amp;v=4" alt="Pablo Alcain" data-reactid="9"/><div class="author-bio-details" data-reactid="10"><strong data-reactid="11">Pablo Alcain</strong><p data-reactid="12">Simple físico de Argentina</p><small data-reactid="13"><a href="https://github.com/pabloalcain" target="_blank" data-reactid="14"><svg aria-hidden="true" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-reactid="15"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" data-reactid="16"></path></svg><!-- react-text: 17 --> <!-- /react-text --><!-- react-text: 18 -->pabloalcain<!-- /react-text --></a></small></div></div><div data-reactid="19"><p>Hace menos de una semana <a href="https://www.theregister.co.uk/2018/01/02/intel_cpu_design_flaw/">se dieron a conocer</a> dos <em>bugs</em> muy grandes y ocultos que afectan a gran parte de los procesadores: <em>meltdown</em> y <em>spectre</em>.
¿Qué hace importante a estos exploits?
Que sean <strong>fundamentales</strong>: no dependen de un sistema operativo o de un programa específico, sino que dependen del procesador.
Incluso uno de ellos (<em>spectre</em>) funcionaría sobre prácticamente cualquier procesador moderno.</p>
<p>En esta entrada vamos a analizar <a href="https://meltdownattack.com/meltdown.pdf"><code>meltdown</code></a>, un bug que estuvo presente <em>en todos los procesadores Intel</em> desde hace 20 años y que asombra por su sencillez.
Más allá del sistema operativo, <code>meltdown</code> permite leer datos sensibles de otros procesos o máquinas virtuales a una velocidad de 500 kb/s.</p>
<p>Pero, para comprender cómo funciona <code>meltdown</code>, primero tenemos que repasar algunos detalles del funcionamiento del procesador.</p>
<h2>Arquitectura del Procesador</h2>
<p>La información que “le pertenece” al procesador se guarda en los llamados <em>registros</em>.<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup>
Sobre éstos puede hacer una cantidad de operaciones, como por ejemplo sumarlos, multiplicarlos, cambiarlos de lugar, etcétera.
Cuáles y cuántos son los registros y qué operaciones puede hacer son, básicamente, la <a href="https://es.wikipedia.org/wiki/Conjunto_de_instrucciones"><strong>arquitectura</strong></a>.
Es un modelo abstracto (básicamente, cómo ve al procesador un programador a través de un <a href="https://es.wikipedia.org/wiki/Lenguaje_ensamblador">lenguaje <em>assembler</em></a>), que no define de forma unívoca cómo se realizan esas operaciones o dónde aparecen los registros, es decir, su implementación.</p>
<p>La implementación de las instrucciones que puede realizar un procesador se llama <a href="https://es.wikipedia.org/wiki/Microarquitectura">microarquitectura</a>.
El estado de esta microarquitectura no es alterable: es decir, y esto es muy importante, <strong>no se puede programar sobre la microarquitectura u obtener su estado</strong>.
Aquí es donde todo se vuelve sutil y complicado y donde se realizan muchas optimizaciones del procesador muy conocidas.
Vamos a explicar tres conceptos de microarquitectura muy importantes en general y, específicamente, para comprender cómo funcionan <em>meltdown</em> y <em>spectre</em>.</p>
<h3>Memoria Cache</h3>
<p>Evidentemente, no toda la información que usa un programa puede estar en los registros del procesador (que, sumados, en general no superan 1 kB de memoria).
Los programas residen, en su gran parte, en la memoria principal (la memoria RAM) y, para realizar operaciones, el procesador <em>trae</em> de la memoria principal los datos que necesita.
Esta solución tiene un inconveniente: un procesador típico tarda 0.2 nanosegundos (un nanosegundo es una mil millonésima parte de un segundo) en realizar una operación, pero el acceso a la memoria principal lleva 100ns.
Para ponerlo en perspectiva, si uno tardara 1 segundo en hacer una suma y quisiera sumar dos números, tendría que esperar <strong>más de 10 minutos</strong> para saber cuáles son los números (5 minutos para cada uno) que va a sumar.
Afortunadamente, este problema se evita generalmente agregando un nuevo tipo de memoria, llamado “memoria cache”.
Esta memoria está en el chip del procesador y es de muy rápido acceso y poca capacidad.
¿Cómo funciona?
Cuando el procesador necesita acceder a una posición de la memoria principal, de paso, trae algunos valores que están cerca de esa posición (a pesar de que no los necesite en ese momento y no sea exactamente el que pidió) a la memoria cache, con la esperanza de que vaya a tener que usarlos pronto.
En nuestro ejemplo, si los números que vamos a sumar están juntos, en vez de 10 minutos, tardaríamos sólo 5.
Si tuviéramos que sumar muchos números que están cerca, la ventaja se vuelve mayor.
Cuando necesitamos un dato de la memoria principal y está en el cache, se conoce como <em>cache hit</em>.
Cuando no está, es un <em>cache miss</em>.</p>
<h3>Ejecución fuera de orden</h3>
<p>Al agregar la memoria cache se reducen mucho las demoras en obtener datos de la memoria principal, pero así y todo los <em>cache misses</em> demoran mucho la ejecución del código.
Supongamos que tenemos secuencialmente las operaciones 1 y 2, donde la operación 1 genera un <em>cache miss</em> y la 2 genera un <em>cache hit</em>.
Si la operación 2 no depende del resultado de la operación 1, no hay problema en que ejecutemos la operación 2 mientras el procesador “va a buscar” la información necesaria para ejecutar la 1.
Entonces, efectivamente, primero se ejecutaría la operación 2, para guardarla en un lugar temporal (perteneciente a la microarquitectura).
Luego, una vez ejecutada la operación 1, <strong>consolida</strong> la operación 2 en el registro adecuado y, así queda en la arquitectura.
En conclusión, la <strong>consolidación</strong> es siempre en el orden explicitado, pero la ejecución puede ser <strong>fuera de orden</strong>.</p>
<h3>Branch prediction</h3>
<p>Imaginemos ahora el caso anterior, pero entre la operación 1 y la 2 hay una sentencia condicional que sí depende del resultado de la operación 1.
Algo así<sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup>:</p>
<div class="gatsby-highlight">
      <pre class="language-c"><code>z <span class="token operator">=</span> a<span class="token operator">*</span>x<span class="token punctuation">;</span> <span class="token comment">// op 1</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>z <span class="token operator">></span> <span class="token number">5</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  w <span class="token operator">=</span> z <span class="token operator">+</span> y<span class="token punctuation">;</span> <span class="token comment">// op 2 primer caso</span>
<span class="token punctuation">}</span>
<span class="token keyword">else</span> <span class="token punctuation">{</span>
  w <span class="token operator">=</span> z <span class="token operator">-</span> y<span class="token punctuation">;</span> <span class="token comment">// op 2 segundo caso</span>
<span class="token punctuation">}</span>
</code></pre>
      </div>
<p>La situación es similar a la anterior, pero ahora, hasta tener el valor de <code>z</code> no sabemos qué operación hacer.
No nos queda otra que esperar al resultado, y ya no podemos ganar tiempo como antes… ¿o sí?
El <em>branch prediction</em> (que forma parte de, en general, la <em>ejecución especulativa</em>) consiste en ejecutar alguna de las dos tratando de predecir qué va a resultar de la condición y guardando el resultado en un lugar temporal.
En caso de que lo hayamos predicho correctamente, <strong>consolidamos</strong> el resultado temporal a <code>w</code>.
Si no, tendremos que recalcular <code>w</code>.
Fíjense que sólo con que el predictor sea al azar (es decir, que aleatoriamente elija con 50% de probabilidades seguir un camino u otro) ya la ejecución especulativa es aceptada la mitad de las veces<sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup>.</p>
<h2>Meltdown: Modificando el estado de la microarquitectura</h2>
<p>Cuando ejecutamos un programa cualquiera, éste no tiene permitido acceder a cualquier lugar de la memoria principal.
Esto es de esperar, ya que si no cualquier programa que ejecutemos podría leer todo lo que estamos ejecutando y obtener, por ejemplo, nuestras claves bancarias.
Así, al intentar acceder a una posición de memoria prohibida (es decir, que no le pertenece al programa que se está ejecutando), se dispara una <em>excepción</em> y la ejecución se detiene.
El objetivo de <code>meltdown</code> es obtener la información de <strong>toda la memoria principal</strong>, a pesar de que su acceso no está permitido.</p>
<p>Con las características que describimos ya es suficiente para entender cómo funciona <code>meltdown</code>.
<strong>IMPORTANTE:</strong> por ahora, para simplificar un poco las cosas, por un rato supongamos que el comportamiento del <em>cache</em> es ligeramente distinto: cuando va a buscar un dato en la memoria principal, trae <strong>sólo a ese dato</strong> a la memoria cache.<sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup></p>
<p>Como es de esperar, es de una sencillez que deslumbra.
El objetivo es leer el byte que está guardado en una posición de memoria inaccesible a nuestro programa (esa posición de memoria la llamamos <code>mem</code>), situada en el espacio de memoria del <em>kernel</em>, que puede acceder a todas las posiciones de la memoria física.
Supongamos que el programa que estamos ejecutando tiene una sección de 256 bytes propios en la memoria principal, que no está alojada en la memoria cache<sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup>.
Dicho en otras palabras, supongamos que tenemos un <code>array</code> de C de 256 bytes de tamaño, al que llamaremos <code>probe</code>.
Ahora ejecutamos las siguientes instrucciones:</p>
<div class="gatsby-highlight">
      <pre class="language-c"><code>x <span class="token operator">=</span> <span class="token operator">*</span>mem<span class="token punctuation">;</span> <span class="token comment">// guardamos en x el contenido de la posición de memoria mem</span>
tmp <span class="token operator">=</span> probe<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre>
      </div>
<p>La primera instrucción, como trata de acceder a una posición de memoria prohibida, dispara una <em>excepción</em> y, efectivamente, <code>x</code> nunca toma el valor que está guardado en <code>mem</code>.
Debido a la ejecución fuera de orden, cuando se carga el valor de <code>mem</code> en <code>x</code>, es probable que el procesador ya haya comenzado a ejecutar la instrucción siguiente como parte de la ejecución fuera de orden y las haya guardado en la posición temporal (recordemos, perteneciente a la microarquitectura).
Como ya mencionamos, la <strong>consolidación</strong> de los datos se realiza en estricto orden, y aquí queda claro por qué.
Es durante la consolidación que se maneja cualquier tipo de excepción.
Como en este caso la primera instrucción genera una excepción, la segunda instrucción no se consolida y, entonces, el valor de <code>probe[x]</code> no queda guardado en ningún lugar de la arquitectura.</p>
<p>Sin embargo, y aquí está el punto jugoso del asunto, la segunda instrucción no se consolidó pero <em>se ejecutó</em>.
Y al ejecutarse, trajo el valor de <code>probe[x]</code> a la memoria cache.
En conclusión, logramos modificar la microarquitectura.</p>
<h2>Meltdown: Obteniendo los secretos</h2>
<p>Una vez que terminamos de ejecutar el código ya mencionado, la microarquitectura queda ligeramente modificada.
Al comienzo de nuestro problema ninguno de los elementos de <code>probe</code> residían en la memoria cache; al terminarlo, <code>probe[x]</code> está en la memoria cache.
¿Podremos aprovechar esto de alguna forma?
Recordemos cuál era todo el punto de tener una memoria cache: los elementos que están en ella se acceden mucho más rápido que en la memoria principal.
Entonces hacemos un pequeño ejercicio: tratamos de acceder a <em>cada uno</em> de los elementos de <code>probe</code> y medimos cuánto tiempo demanda ese acceso.
Al realizar esta medición observamos que el acceso a todas las posiciones <code>i</code> de <code>probe[i]</code> llevan cerca de <code>100 ns</code>, excepto el acceso a <code>probe[84]</code> que tarda sensiblemente menos.
¿Qué pasó?
Simple: pasó que <code>probe[84]</code> estaba ya guardado en el cache y entonces fue más rápido acc--- ¡un momento!
Si <code>probe[x]</code> estaba en el cache luego de ejecutar las instrucciones que mencionamos y ahora vemos que <code>probe[84]</code> está en la cache… eso quiere decir que x es 84.
¡Es decir que lo que estaba en esa memoria inaccesible era 84!</p>
<h2>Detalles que no tuvimos en cuenta</h2>
<h3>El comportamiento real de la cache</h3>
<p>El ejemplo de <code>meltdown</code> que dimos suponía un comportamiento ligeramente diferente de la cache, en el que sólo traía el valor pedido.
En realidad, trae una sección de <code>n</code> bytes<sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup> contigua al valor pedido (llamado tamaño de página de memoria).
La solución, igual, es sencillísima: el array <code>probe</code> tiene tamaño <code>256*n</code> (es decir, de tamaño igual a 256 páginas) y el acceso lo hacemos a <code>probe[x*n]</code>.
Así nos garantizamos que cada acceso defina unívocamente a una página del cache<sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup>.</p>
<h3>Bueno, pero el programa efectivamente dispara una excepción</h3>
<p>Sí, es cierto, pero hay varias soluciones posibles:</p>
<ol>
<li>
<p>Que el programa, en vez de ejecutar el código, lance un sub-proceso que lo ejecute.
Así, cuando ese sub-proceso dispara la excepción (un <em>segmentation fault</em> o <code>SIGSEGV</code>), el control puede seguir en el programa original.</p>
</li>
<li>
<p>Usar un <em>handle</em> para manejar la señal; por ejemplo <a href="https://www.gnu.org/software/libsigsegv/">libsigsegv</a>.</p>
</li>
<li>
<p>Que el código se ejecute después de un condicional que se prediga incorrectamente.
De esta forma, se ejecuta especulativamente pero <strong>nunca</strong> se consolida y, como las excepciones se disparan al consolidar las operaciones, nunca obtenemos una excepción.</p>
</li>
<li>
<p>Suprimir la excepción con <a href="https://software.intel.com/en-us/node/524022">Intel TSX</a>, una implementación de memoria transaccional en hardware que, dicho mal y pronto, permite que múltiples instrucciones se agrupen en una <em>transacción</em> que, si falla, revierte las operaciones hechas pero no dispara ninguna excepción.</p>
</li>
</ol>
<h3>¿Y si se dispara la excepción antes de la ejecución posterior?</h3>
<p>Cuando describíamos <code>meltdown</code> dijimos: “Debido a la ejecución fuera de orden, cuando se carga el valor de <code>mem</code> en <code>x</code>, es probable que el procesador ya haya comenzado a ejecutar la instrucción siguiente como parte de la ejecución fuera de orden y las haya guardado en la posición temporal (recordemos, perteneciente a la microarquitectura).”</p>
<p>Es decir, si es probable que ya haya comenzado a ejecutar la instrucción siguiente, también es probable que no lo haya hecho.
Cuando se dispara la excepción <strong>todos</strong> los registros se hacen cero<sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup>, y <code>x</code> es un registro.
La solución es entonces que trate de leer el valor guarado en <code>mem</code> siempre que <code>x</code> no sea cero.</p>
<h2>Resultados de meltdown</h2>
<p>Los resultados de <code>meltdown</code> son asombrosos: lee correctamente el 99.98% de la memoria prohibida a una velocidad de 500 kb/s.
Funciona en todos los procesadores de Intel probados, pero no en los AMD.
Esto se puede deber a varios motivos, como por ejemplo que en esas microarquitecturas el tamaño de los <em>buffers</em> utilizados para la ejecución fuera de orden sean muy pequeños y la excepción se dispare siempre antes de que se ejecuten las operaciones posteriores.
Afortunadamente <em>meltdown</em> tiene una solución en el corto plazo llamada KAISER, que evita que, para el espacio de memoria del usuario, exista una posición de memoria que vaya al <em>kernel</em>.
A pesar de que la solución no es total y todavía deja algunas vulnerabilidades, mitiga bastante el efecto de <code>meltdown</code>.
¿El costo?
Los programas podrían ser hasta un 30% más lentos.</p>
<h2>Conclusión</h2>
<p><code>meltdown</code> es un bug que estuvo presente desde hace 20 años, todo terreno y que, como dijimos, asombra por su sencillez.
Sin la necesidad de vulnerabilidades de software e independientemente del sistema operativo, <code>meltdown</code> permite leer datos sensibles de otros procesos o máquinas virtuales a una velocidad de 500 kb/s.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn-1">
<p>Claro que la información de la “computadora” propiamente dicha también se encuentra en, por ejemplo, la memoria RAM.</p>
<a href="#fnref-1" class="footnote-backref">↩</a>
</li>
<li id="fn-2">
<p>Esto es una cuestión conceptual. Los saltos condicionales y las asignaciones son un poco distintas en la arquitectura.</p>
<a href="#fnref-2" class="footnote-backref">↩</a>
</li>
<li id="fn-3">
<p>Hoy en día los predictores tienen una precisión de aproximadamente <a href="https://www.ece.cmu.edu/~ece447/s13/lib/exe/fetch.php?media=onur-447-spring13-lecture11-branch-prediction-afterlecture.pdf">95%</a></p>
<a href="#fnref-3" class="footnote-backref">↩</a>
</li>
<li id="fn-4">
<p>La generalización para los casos en los que el cache trae más de un dato funcionan con una muy ligera variación.</p>
<a href="#fnref-4" class="footnote-backref">↩</a>
</li>
<li id="fn-5">
<p>Esto se puede lograr de muchas maneras, pero de cualquier modo cuando se ejecuta el programa, el <code>array</code> comienza localizado en la memoria principal y fuera de la cache.</p>
<a href="#fnref-5" class="footnote-backref">↩</a>
</li>
<li id="fn-6">
<p>El valor típico para la mayoría de los sistemas operativos es 4kb.</p>
<a href="#fnref-6" class="footnote-backref">↩</a>
</li>
<li id="fn-7">
<p>Visto de esta forma, podemos suponer que el cache imaginario que inventamos era para un sistema con un tamaño de página de 1 byte.</p>
<a href="#fnref-7" class="footnote-backref">↩</a>
</li>
<li id="fn-8">
<p>Esto es esperable porque hay que borrar cualquier información prohibida que se haya guardado en los registros.</p>
<a href="#fnref-8" class="footnote-backref">↩</a>
</li>
</ol>
</div></div><div id="comments" data-reactid="20"><div data-reactid="21"><div id="disqus_thread" data-reactid="22"></div></div></div></div><hr data-reactid="23"/><footer data-reactid="24"><small data-reactid="25">
      Un blog de programación científica enfocado en high performance computing
    </small><div style="padding:0.725rem;font-size:[object Object];" data-reactid="26"><a href="/meltdown/about" data-reactid="27">Acerca de</a><br data-reactid="28"/><a href="/" data-reactid="29">Artículos</a><br data-reactid="30"/><a href="https://github.com/sci-prog/sci-prog.github.io" target="_blank" data-reactid="31">Github repo</a><br data-reactid="32"/><a href="https://facebook.com/sciprog/" target="_blank" data-reactid="33">Facebook</a></div></footer><span style="display:block;clear:both;" data-reactid="34"> </span></div></div><script id="webpack-manifest">/*<![CDATA[*/window.webpackManifest={"231608221292675":"app-5204eebb1ac2e4e0fdd9.js","99219681209289":"component---node-modules-gatsby-plugin-offline-app-shell-js-5c4c5a0f7af9dc69d6d7.js","107818501498521":"component---src-templates-blog-post-js-27856d6eb5844d506e82.js","263791100135453":"component---src-pages-about-js-df9cc190a4929654e9cf.js","35783957827783":"component---src-pages-index-js-25bb7c6115f3c46893ef.js","60335399758886":"path----557518bd178906f8d58a.js","210333531512890":"path---offline-plugin-app-shell-fallback-a0e39f21c11f6a62c5ab.js","263240134119636":"path---contributor-guide-44efdbe6307dd8285123.js","194907401706789":"path---git-intro-90e1d0ec2c49c52a8c0d.js","109517562881362":"path---meltdown-36ea1df735d2937b866a.js","30792937111940":"path---numpy-intro-a13a2c6d4a0dab30ede9.js","87572157768998":"path---rust-intro-ad1fe339552b33448e27.js","273950069227526":"path---about-44b11b110605667000db.js","142629428675168":"path---index-4631b2c8316e3b823940.js","114276838955818":"component---src-layouts-index-js-65ee3ce0b05326dad154.js"}/*]]>*/</script><script>
  
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-109737731-1', 'auto');
  </script><script>/*<![CDATA[*/!function(e,t,r){function n(){for(;d[0]&&"loaded"==d[0][f];)c=d.shift(),c[o]=!i.parentNode.insertBefore(c,i)}for(var s,a,c,d=[],i=e.scripts[0],o="onreadystatechange",f="readyState";s=r.shift();)a=e.createElement(t),"async"in i?(a.async=!1,e.head.appendChild(a)):i[f]?(d.push(a),a[o]=n):e.write("<"+t+' src="'+s+'" defer></'+t+">"),a.src=s}(document,"script",["/commons-3cf304937523a964e309.js","/app-5204eebb1ac2e4e0fdd9.js","/path---meltdown-36ea1df735d2937b866a.js","/component---src-templates-blog-post-js-27856d6eb5844d506e82.js","/component---src-layouts-index-js-65ee3ce0b05326dad154.js"])/*]]>*/</script></body></html>